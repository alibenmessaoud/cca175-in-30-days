# CCA-175: Chapter 14

### DataFrames and Apache Spark SQL

- Spark SQL?

  - module to process structured data, replace shark (deprecated), built on top of core
  - API to work with dat as tables: DataFrame + SQL engine

- SQL Context

  - Main entry to get SQL context

  - 2 impls: 

    - SQLContext (basic) 
    - HiveContext (recommended)
      - RW Hive/ HCatalog tables directly
      - Support HiveQL
      - Requires link between app and Hive APIs

  - Create

    ```scala
    from pyspark.sql import HiveContext
    sqlContext = HiveContext(sc)
    
    import org.apache.spark.sql.hive.HiveContext
    val sqlContext = new HiveContext(sc)
    import sqlContext.implicits._
    ```

- DataFrames

  - Main abstraction in Spark SQL ~ RDD in core Spark
  - Distributed collection of data organized into named columns
  - Built on a base RDD containing row objects
  - 

### Essentials

- â€‹